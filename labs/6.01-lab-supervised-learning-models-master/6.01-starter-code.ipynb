{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./401ksubs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years worked full time, Education, info on other investments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're attempting to target someone for a service, \n",
    "# especially one that could benefit an inidivual, using race\n",
    "# to measure who should or should not qualify for such benefits\n",
    "# would potentially exclude people from the benfits on the basis\n",
    "# of race, which is highly unethical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income and income squared, likely, as they could both perfectly predict income,\n",
    "# because they are income. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "      <td>9275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.392129</td>\n",
       "      <td>39.254641</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.204420</td>\n",
       "      <td>41.080216</td>\n",
       "      <td>2.885067</td>\n",
       "      <td>19.071675</td>\n",
       "      <td>0.276226</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>2121.192483</td>\n",
       "      <td>1793.652722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488252</td>\n",
       "      <td>24.090002</td>\n",
       "      <td>0.483213</td>\n",
       "      <td>0.403299</td>\n",
       "      <td>10.299517</td>\n",
       "      <td>1.525835</td>\n",
       "      <td>63.963838</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>3001.469424</td>\n",
       "      <td>895.648841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-502.302000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.160100</td>\n",
       "      <td>625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>469.155600</td>\n",
       "      <td>1089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.288000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1108.091000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.449500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2516.025500</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>199.041000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1536.798000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39617.320000</td>\n",
       "      <td>4096.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             e401k          inc         marr         male          age  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000  9275.000000   \n",
       "mean      0.392129    39.254641     0.628571     0.204420    41.080216   \n",
       "std       0.488252    24.090002     0.483213     0.403299    10.299517   \n",
       "min       0.000000    10.008000     0.000000     0.000000    25.000000   \n",
       "25%       0.000000    21.660000     0.000000     0.000000    33.000000   \n",
       "50%       0.000000    33.288000     1.000000     0.000000    40.000000   \n",
       "75%       1.000000    50.160000     1.000000     0.000000    48.000000   \n",
       "max       1.000000   199.041000     1.000000     1.000000    64.000000   \n",
       "\n",
       "             fsize       nettfa        p401k         pira         incsq  \\\n",
       "count  9275.000000  9275.000000  9275.000000  9275.000000   9275.000000   \n",
       "mean      2.885067    19.071675     0.276226     0.254340   2121.192483   \n",
       "std       1.525835    63.963838     0.447154     0.435513   3001.469424   \n",
       "min       1.000000  -502.302000     0.000000     0.000000    100.160100   \n",
       "25%       2.000000    -0.500000     0.000000     0.000000    469.155600   \n",
       "50%       3.000000     2.000000     0.000000     0.000000   1108.091000   \n",
       "75%       4.000000    18.449500     1.000000     1.000000   2516.025500   \n",
       "max      13.000000  1536.798000     1.000000     1.000000  39617.320000   \n",
       "\n",
       "             agesq  \n",
       "count  9275.000000  \n",
       "mean   1793.652722  \n",
       "std     895.648841  \n",
       "min     625.000000  \n",
       "25%    1089.000000  \n",
       "50%    1600.000000  \n",
       "75%    2304.000000  \n",
       "max    4096.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9275 entries, 0 to 9274\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   e401k   9275 non-null   int64  \n",
      " 1   inc     9275 non-null   float64\n",
      " 2   marr    9275 non-null   int64  \n",
      " 3   male    9275 non-null   int64  \n",
      " 4   age     9275 non-null   int64  \n",
      " 5   fsize   9275 non-null   int64  \n",
      " 6   nettfa  9275 non-null   float64\n",
      " 7   p401k   9275 non-null   int64  \n",
      " 8   pira    9275 non-null   int64  \n",
      " 9   incsq   9275 non-null   float64\n",
      " 10  agesq   9275 non-null   int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 797.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e401k     0\n",
       "inc       0\n",
       "marr      0\n",
       "male      0\n",
       "age       0\n",
       "fsize     0\n",
       "nettfa    0\n",
       "p401k     0\n",
       "pira      0\n",
       "incsq     0\n",
       "agesq     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119bbc210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Income quared and age squared. Perhaps this was done to assure a more normal \n",
    "# distribtion of the variables, or perhaps some expert was aware of a relationship\n",
    "# between incsq and other variables that did not present itself in inc alone.\n",
    "\n",
    "df['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11c0a3810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['agesq'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bfecc50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAY00lEQVR4nO3df4xd5X3n8fcnNj8shtpQ2Luu7a3djdsVwaqBERAlrWbCBhunjUk3jcxaYCdE00pGShTvFtOoCw1B62xx6KISuhPZi8mviZsEMTJmqeswGyGt+WHiMLYJ6wkYxSNjb7ExmeCiHfa7f9xnvJfh3pk793f2+bykq3vOc55zzvecufO555577r2KCMzMLA/va3cBZmbWOg59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMVB36kmZJ+rGknWl8iaSnJY1I+q6kc1P7eWl8JE1fXLKMO1L7S5JWNHpjzMxsajM50v8c8GLJ+FeA+yLi/cAp4NbUfitwKrXfl/oh6TJgDfABYCXwNUmz6ivfzMxmQtV8OEvSQmA7cA/wBeAPgf8F/POIGJf0QeCuiFgh6Yk0/D8kzQZeAy4FNgFExH9Myzzbr9J6L7nkkli8eHE929dUv/zlL7ngggvaXUZFrq9+nV6j66tPp9cHtdW4b9++f4yIS8tNm13lMv4a+DPgwjT+68AbETGexo8CC9LwAuDnAOkJ4XTqvwDYW7LM0nnOktQH9AEUCgXuvffeKktsvbGxMbq6utpdRkWur36dXqPrq0+n1we11djb2/tqpWnThr6kPwBORMQ+ST0zWnMNIqIf6Afo7u6Onp6mr7JmQ0NDuL7adXp90Pk1ur76dHp90PgaqznS/xDwcUmrgPOBXwP+MzBP0ux0tL8QGE39R4FFwNF0emcu8HpJ+4TSeczMrAWmfSM3Iu6IiIURsZjiG7E/jIi1wJPAJ1O3dcCjaXgwjZOm/zCKbxwMAmvS1T1LgKXAMw3bEjMzm1a15/TLuR0YkPRl4MfA1tS+FfiGpBHgJMUnCiLioKQdwCFgHNgQEe/UsX4zM5uhGYV+RAwBQ2n4ZeDqMn3+CfjjCvPfQ/EKIDMzawN/ItfMLCMOfTOzjDj0zcwy4tA3M8tIPVfvdLzFmx5r6vI3LhtnfZl1HNn8saau18ysVj7SNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLyLShL+l8Sc9I+omkg5L+MrU/JOkVSfvTbXlql6T7JY1IekHSlSXLWifpcLqtq7ROMzNrjmq+Wvlt4CMRMSbpHOApSY+naf8+Ir43qf8NwNJ0uwZ4ELhG0sXAnUA3EMA+SYMRcaoRG2JmZtOb9kg/isbS6DnpFlPMshp4OM23F5gnaT6wAtgdESdT0O8GVtZXvpmZzYQipsrv1EmaBewD3g88EBG3S3oI+CDFVwJ7gE0R8bakncDmiHgqzbsHuB3oAc6PiC+n9r8AzkTEvZPW1Qf0ARQKhasGBgZq3rjh0dM1z1uNwhw4fua97csWzG3qeqs1NjZGV1dXu8uoqNPrg86v0fXVp9Prg9pq7O3t3RcR3eWmVfXLWRHxDrBc0jzgEUmXA3cArwHnAv0Ug/1LM6qs/Lr60/Lo7u6Onp6empdV7letGmnjsnG2DL93Fx5Z29PU9VZraGiIevZfs3V6fdD5Nbq++nR6fdD4Gmd09U5EvAE8CayMiGPpFM7bwH8Frk7dRoFFJbMtTG2V2s3MrEWquXrn0nSEj6Q5wEeBn6bz9EgScCNwIM0yCNySruK5FjgdEceAJ4DrJV0k6SLg+tRmZmYtUs3pnfnA9nRe/33AjojYKemHki4FBOwH/jT13wWsAkaAt4BPA0TESUl3A8+mfl+KiJON2xQzM5vOtKEfES8AV5Rp/0iF/gFsqDBtG7BthjWamVmD+BO5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWWkmh9GP1/SM5J+IumgpL9M7UskPS1pRNJ3JZ2b2s9L4yNp+uKSZd2R2l+StKJZG2VmZuVVc6T/NvCRiPhdYDmwUtK1wFeA+yLi/cAp4NbU/1bgVGq/L/VD0mXAGuADwErga+nH1s3MrEWmDf0oGkuj56RbAB8BvpfatwM3puHVaZw0/TpJSu0DEfF2RLwCjABXN2QrzMysKoqI6TsVj8j3Ae8HHgD+CtibjuaRtAh4PCIul3QAWBkRR9O0nwHXAHeleb6Z2remeb43aV19QB9AoVC4amBgoOaNGx49XfO81SjMgeNn3tu+bMHcpq63WmNjY3R1dbW7jIo6vT7o/BpdX306vT6orcbe3t59EdFdbtrsahYQEe8AyyXNAx4B/tWMKpiBiOgH+gG6u7ujp6en5mWt3/RYg6oqb+OycbYMv3cXHlnb09T1VmtoaIh69l+zdXp90Pk1ur76dHp90PgaZ3T1TkS8ATwJfBCYJ2ki8RYCo2l4FFgEkKbPBV4vbS8zj5mZtUA1V+9cmo7wkTQH+CjwIsXw/2Tqtg54NA0PpnHS9B9G8RzSILAmXd2zBFgKPNOoDTEzs+lVc3pnPrA9ndd/H7AjInZKOgQMSPoy8GNga+q/FfiGpBHgJMUrdoiIg5J2AIeAcWBDOm1kZmYtMm3oR8QLwBVl2l+mzNU3EfFPwB9XWNY9wD0zL9PMzBqhqjdybWYWN/kN5Kkc2fyxtq3bzDqfv4bBzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwj1fww+iJJT0o6JOmgpM+l9rskjUran26rSua5Q9KIpJckrShpX5naRiRtas4mmZlZJdX8XOI4sDEinpd0IbBP0u407b6IuLe0s6TLKP4Y+geA3wD+QdJvp8kPAB8FjgLPShqMiEON2BAzM5teNT+Mfgw4loZ/IelFYMEUs6wGBiLibeAVSSP8vx9QH0k/qI6kgdTXoW9m1iKKiOo7S4uBHwGXA18A1gNvAs9RfDVwStLfAHsj4ptpnq3A42kRKyPis6n9ZuCaiLht0jr6gD6AQqFw1cDAQK3bxvDo6ZrnrUZhDhw/09RVzNiyBXPPDo+NjdHV1dXGaqbW6fVB59fo+urT6fVBbTX29vbui4juctOqOb0DgKQu4PvA5yPiTUkPAncDke63AJ+ZUWVlREQ/0A/Q3d0dPT09NS9r/abH6i1nShuXjbNluOpd2BJH1vacHR4aGqKe/ddsnV4fdH6Nrq8+nV4fNL7GqhJL0jkUA/9bEfEDgIg4XjL968DONDoKLCqZfWFqY4p2MzNrgWqu3hGwFXgxIr5a0j6/pNsngANpeBBYI+k8SUuApcAzwLPAUklLJJ1L8c3ewcZshpmZVaOaI/0PATcDw5L2p7Y/B26StJzi6Z0jwJ8ARMRBSTsovkE7DmyIiHcAJN0GPAHMArZFxMEGbouZmU2jmqt3ngJUZtKuKea5B7inTPuuqeYzM7Pm8idyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tINT+MvkjSk5IOSToo6XOp/WJJuyUdTvcXpXZJul/SiKQXJF1Zsqx1qf9hSeuat1lmZlZONUf648DGiLgMuBbYIOkyYBOwJyKWAnvSOMANwNJ06wMehOKTBHAncA1wNXDnxBOFmZm1xrShHxHHIuL5NPwL4EVgAbAa2J66bQduTMOrgYejaC8wT9J8YAWwOyJORsQpYDewsqFbY2ZmU5rROX1Ji4ErgKeBQkQcS5NeAwppeAHw85LZjqa2Su1mZtYis6vtKKkL+D7w+Yh4U9LZaRERkqIRBUnqo3haiEKhwNDQUM3L2rhsvBElVVSY0/x1zFTp/hobG6tr/zVbp9cHnV+j66tPp9cHja+xqtCXdA7FwP9WRPwgNR+XND8ijqXTNydS+yiwqGT2haltFOiZ1D40eV0R0Q/0A3R3d0dPT8/kLlVbv+mxmuetxsZl42wZrvp5syWOrO05Ozw0NEQ9+6/ZOr0+6PwaXV99Or0+aHyN1Vy9I2Ar8GJEfLVk0iAwcQXOOuDRkvZb0lU81wKn02mgJ4DrJV2U3sC9PrWZmVmLVHOY+iHgZmBY0v7U9ufAZmCHpFuBV4FPpWm7gFXACPAW8GmAiDgp6W7g2dTvSxFxsiFbYWZmVZk29CPiKUAVJl9Xpn8AGyosaxuwbSYFmplZ4/gTuWZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpaRaUNf0jZJJyQdKGm7S9KopP3ptqpk2h2SRiS9JGlFSfvK1DYiaVPjN8XMzKZTzZH+Q8DKMu33RcTydNsFIOkyYA3wgTTP1yTNkjQLeAC4AbgMuCn1NTOzFpo9XYeI+JGkxVUubzUwEBFvA69IGgGuTtNGIuJlAEkDqe+hGVdsZmY1U0RM36kY+jsj4vI0fhewHngTeA7YGBGnJP0NsDcivpn6bQUeT4tZGRGfTe03A9dExG1l1tUH9AEUCoWrBgYGat644dHTNc9bjcIcOH6mqauYsWUL5p4dHhsbo6urq43VTK3T64POr9H11afT64Paauzt7d0XEd3lpk17pF/Bg8DdQKT7LcBnalzWu0REP9AP0N3dHT09PTUva/2mxxpRUkUbl42zZbjWXdgcR9b2nB0eGhqinv3XbJ1eH3R+ja6vPp1eHzS+xpoSKyKOTwxL+jqwM42OAotKui5MbUzRbmZmLVJT6EuaHxHH0ugngIkrewaBb0v6KvAbwFLgGUDAUklLKIb9GuDf1lO4lbe45NXNxmXjTX+1M+HI5o+1ZD1mVp9pQ1/Sd4Ae4BJJR4E7gR5Jyyme3jkC/AlARByUtIPiG7TjwIaIeCct5zbgCWAWsC0iDjZ8a8zMbErVXL1zU5nmrVP0vwe4p0z7LmDXjKozM7OG8idyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8vItKEvaZukE5IOlLRdLGm3pMPp/qLULkn3SxqR9IKkK0vmWZf6H5a0rjmbY2ZmU6nmSP8hYOWktk3AnohYCuxJ4wA3AEvTrQ94EIpPEhR/UP0a4GrgzoknCjMza51pQz8ifgScnNS8GtiehrcDN5a0PxxFe4F5kuYDK4DdEXEyIk4Bu3nvE4mZmTWZImL6TtJiYGdEXJ7G34iIeWlYwKmImCdpJ7A5Ip5K0/YAtwM9wPkR8eXU/hfAmYi4t8y6+ii+SqBQKFw1MDBQ88YNj56ued5qFObA8TNNXUVdWlnfsgVzZzzP2NgYXV1dTaimcTq9RtdXn06vD2qrsbe3d19EdJebNrvegiIiJE3/zFH98vqBfoDu7u7o6empeVnrNz3WoKrK27hsnC3Dde/CpmllfUfW9sx4nqGhIer5+7ZCp9fo+urT6fVB42us9eqd4+m0Den+RGofBRaV9FuY2iq1m5lZC9Ua+oPAxBU464BHS9pvSVfxXAucjohjwBPA9ZIuSm/gXp/azMyshaZ97S/pOxTPyV8i6SjFq3A2Azsk3Qq8Cnwqdd8FrAJGgLeATwNExElJdwPPpn5fiojJbw6bmVmTTRv6EXFThUnXlekbwIYKy9kGbJtRdWZm1lD+RK6ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llpHN/4NV+pSyu4feINy4br/t3jI9s/lhd85vlxkf6ZmYZceibmWWkrtCXdETSsKT9kp5LbRdL2i3pcLq/KLVL0v2SRiS9IOnKRmyAmZlVrxFH+r0RsTwiutP4JmBPRCwF9qRxgBuApenWBzzYgHWbmdkMNOP0zmpgexreDtxY0v5wFO0F5kma34T1m5lZBYqI2meWXgFOAQH8l4jol/RGRMxL0wWcioh5knYCmyPiqTRtD3B7RDw3aZl9FF8JUCgUrhoYGKi5vuHR0zXPW43CHDh+pqmrqEsO9S1bMLcxxVQwNjZGV1dXU9dRD9dXn06vD2qrsbe3d1/J2Zd3qfeSzQ9HxKikfwbslvTT0okREZJm9KwSEf1AP0B3d3f09PTUXFy9lwNOZ+OycbYMd+5VrznUd2RtT2OKqWBoaIh6HoPN5vrq0+n1QeNrrOv0TkSMpvsTwCPA1cDxidM26f5E6j4KLCqZfWFqMzOzFqk59CVdIOnCiWHgeuAAMAisS93WAY+m4UHglnQVz7XA6Yg4VnPlZmY2Y/W8ti4AjxRP2zMb+HZE/DdJzwI7JN0KvAp8KvXfBawCRoC3gE/XsW4zM6tBzaEfES8Dv1um/XXgujLtAWyodX1mZlY/fyLXzCwjDn0zs4w49M3MMuLQNzPLSOd+csesCrV8j/9MTPWd//4uf/tV5CN9M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLir2Ewq1GzvwKiEn/9g9XDR/pmZhlx6JuZZaTloS9ppaSXJI1I2tTq9ZuZ5ayl5/QlzQIeAD4KHAWelTQYEYdaWYfZr7LS9xKm+urnTtCo+vw+RuO0+o3cq4GR9KPqSBoAVgMOfTOrqFlvmlfzpPT/2xOOIqJ1K5M+CayMiM+m8ZuBayLitpI+fUBfGv0d4KWWFThzlwD/2O4ipuD66tfpNbq++nR6fVBbjb8ZEZeWm9Bxl2xGRD/Q3+46qiHpuYjobncdlbi++nV6ja6vPp1eHzS+xla/kTsKLCoZX5jazMysBVod+s8CSyUtkXQusAYYbHENZmbZaunpnYgYl3Qb8AQwC9gWEQdbWUODdfppKNdXv06v0fXVp9PrgwbX2NI3cs3MrL38iVwzs4w49M3MMuLQr4KkRZKelHRI0kFJn0vtd0kalbQ/3Va1uc4jkoZTLc+ltosl7ZZ0ON1f1KbafqdkP+2X9Kakz7dzH0raJumEpAMlbWX3l4ruT18f8oKkK9tU319J+mmq4RFJ81L7YklnSvbj3za7vilqrPg3lXRH2ocvSVrRpvq+W1LbEUn7U3vL9+EU2dK8x2FE+DbNDZgPXJmGLwT+J3AZcBfw79pdX0mdR4BLJrX9J2BTGt4EfKUD6pwFvAb8Zjv3IfD7wJXAgen2F7AKeBwQcC3wdJvqux6YnYa/UlLf4tJ+bd6HZf+m6X/mJ8B5wBLgZ8CsVtc3afoW4D+0ax9OkS1Nexz6SL8KEXEsIp5Pw78AXgQWtLeqqq0Gtqfh7cCNbaxlwnXAzyLi1XYWERE/Ak5Oaq60v1YDD0fRXmCepPmtri8i/j4ixtPoXoqfdWmbCvuwktXAQES8HRGvACMUv5qlaaaqT5KATwHfaWYNU5kiW5r2OHToz5CkxcAVwNOp6bb0Mmtbu06dlAjg7yXtS19nAVCIiGNp+DWg0J7S3mUN7/5H66R9WGl/LQB+XtLvKO1/4v8MxaO+CUsk/VjSf5f0e+0qKin3N+20ffh7wPGIOFzS1rZ9OClbmvY4dOjPgKQu4PvA5yPiTeBB4F8Cy4FjFF8qttOHI+JK4AZgg6TfL50YxdeHbb1GV8UP5X0c+LvU1Gn78KxO2F+VSPoiMA58KzUdA/5FRFwBfAH4tqRfa1N5Hfs3neQm3n3w0bZ9WCZbzmr049ChXyVJ51D8o3wrIn4AEBHHI+KdiPg/wNdp8kvV6UTEaLo/ATyS6jk+8fIv3Z9oX4VA8Qnp+Yg4Dp23D6m8vzrmK0QkrQf+AFibAoF0yuT1NLyP4vny325HfVP8TTtpH84G/gj47kRbu/ZhuWyhiY9Dh34V0rm/rcCLEfHVkvbSc2mfAA5MnrdVJF0g6cKJYYpv+B2g+DUX61K3dcCj7anwrHcdXXXSPkwq7a9B4JZ09cS1wOmSl98tI2kl8GfAxyPirZL2S1X8vQok/RawFHi51fWl9Vf6mw4CaySdJ2kJxRqfaXV9yb8GfhoRRyca2rEPK2ULzXwctvKd6l/VG/Bhii+vXgD2p9sq4BvAcGofBOa3scbfonhlxE+Ag8AXU/uvA3uAw8A/ABe3scYLgNeBuSVtbduHFJ98jgH/m+K50Vsr7S+KV0s8QPHobxjoblN9IxTP6U48Dv829f036e++H3ge+MM27sOKf1Pgi2kfvgTc0I76UvtDwJ9O6tvyfThFtjTtceivYTAzy4hP75iZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlG/i9qBvxML/Y/XwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['inc'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11c00d990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['incsq'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both income and age are described as as the squares of their values. \n",
    "# The correct description for these should be age in years and income in thousands of dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple linear regression --yes, can interpret feature impact\n",
    "# knn --no, cannot interpret feature impact\n",
    "# decision tree --yes, can interpret feature impact\n",
    "# extra trees --yes, can interpret feature impact\n",
    "# bagging with decision trees --yes, can interpret feature impact\n",
    "# Adaboost model --yes, can interpret feature impact\n",
    "# XGBoost model --yes, can interpret feature impact\n",
    "# SVM regression --yes, can interpret feature impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y:\n",
    "\n",
    "X = df.drop(columns=[\"e401k\", \"p401k\", \"inc\", \"incsq\", \"pira\"])\n",
    "y = df[\"inc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test Split:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit MLR:\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit KNN:\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit CART:\n",
    "\n",
    "cart = DecisionTreeRegressor()\n",
    "cart.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                 n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                 warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit bagging:\n",
    "\n",
    "bag = BaggingRegressor()\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Random Forest:\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                  n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Adaboost:\n",
    "\n",
    "adb = AdaBoostRegressor()\n",
    "adb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM:\n",
    "\n",
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random resampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decision tree takes the best split in a feature.\n",
    "# Bagged decision rees use bootstrap aggregation. Multiple trees are averaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests ==> only a subset of features are selected at random and the best split feature from the\n",
    "# subset is used to split each node in a tree. \n",
    "# Bagging ==> all features are considered for splitting a node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Becasue feature selection of random forests is random, individual trees tend to \n",
    "# be less correlated, resuklting in less variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries: \n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to return RMSE of scored models:\n",
    "\n",
    "def rmse_score(model, X_train, X_test, y_train, y_test):\n",
    "    mse_train = mean_squared_error(y_true = y_train, y_pred = model.predict(X_train))\n",
    "    mse_test = mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))\n",
    "    rmse_train = mse_train ** 0.5\n",
    "    rmse_test = mse_test ** 0.5\n",
    "    \n",
    "    print(f'Train RMSE: {rmse_train}')\n",
    "    print(f'Test RMSE: {rmse_test}')\n",
    "    return (rmse_train, rmse_test)\n",
    "\n",
    "# Code adapted from GA DSI Lab 6.01 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 20.086432991271494\n",
      "Test RMSE: 20.981222872070013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.086432991271494, 20.981222872070013)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rmse_score(lr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 17.09983276782106\n",
      "Test RMSE: 21.475481552594076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17.09983276782106, 21.475481552594076)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 2.2981381078557472\n",
      "Test RMSE: 27.188829300457005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.2981381078557472, 27.188829300457005)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(cart, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 8.880190953763814\n",
      "Test RMSE: 21.033321317012692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.880190953763814, 21.033321317012692)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(bag, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 7.715743943178125\n",
      "Test RMSE: 20.45269872890559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.715743943178125, 20.45269872890559)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 23.31667980699543\n",
      "Test RMSE: 24.236096659891555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.31667980699543, 24.236096659891555)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(adb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 23.48620507770086\n",
      "Test RMSE: 24.055846528936915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.48620507770086, 24.055846528936915)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_score(svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They're all overfit. Training RMSE is consistently lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably linear regression, as it has a relatively smaller gap between training and testing RMSE, and is easily interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could search for more data, consider variable transformations, or use GridSearch to optimize hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're attemptiong to predict whether someone has a 401k, it doesn't make sense to include a \n",
    "# variable describing the very thing we're trying to predict--it wouild \n",
    "# confound our results and obscure the meaning/impact of other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression, K-nearest neighbors, Naive Bayes, \n",
    "# Decision trees, Baggiong, Random forest, Extra trees, Adaboost, XGBoost, and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y:\n",
    "\n",
    "X = df.drop(columns=['e401k', 'p401k'])\n",
    "y = df['e401k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data:\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN:\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cart:\n",
    "\n",
    "cart = DecisionTreeClassifier()\n",
    "cart.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging:\n",
    "\n",
    "bag = BaggingClassifier()\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest:\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboost:\n",
    "\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector:\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FP = indidviduals incorrectly predicted as eligible, \n",
    "# FN = indidviduals incorrectly predicted to be inelgible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I imagine a business would want to minimize false positives for purposes of \n",
    "# saving money, but from a social perspective, I would rather more people have access\n",
    "# to 401(k)s, and would thus choose to minimize false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The f-1 score is intended to balance FPs and FNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to score models:\n",
    "\n",
    "def f1(model, X_train, X_test, y_train, y_test):\n",
    "    f1_train = f1_score(y_true = y_train, y_pred = model.predict(X_train))\n",
    "    f1_test = f1_score(y_true = y_test, y_pred = model.predict(X_test))\n",
    "    \n",
    "    print('F1 train: '  + str(model.__class__.__name__) + ' : ' + str(f1_train))\n",
    "    print('F1 test: ' + str(model.__class__.__name__) + ' : ' + str(f1_test))\n",
    "    \n",
    "# Code adapted from 6.01 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 train: LogisticRegression : 0.4822048611111111\n",
      "F1 test: LogisticRegression : 0.4708994708994709\n",
      "F1 train: KNeighborsClassifier : 0.6587677725118484\n",
      "F1 test: KNeighborsClassifier : 0.49910017996400713\n",
      "F1 train: DecisionTreeClassifier : 1.0\n",
      "F1 test: DecisionTreeClassifier : 0.48226950354609927\n",
      "F1 train: BaggingClassifier : 0.9735074626865671\n",
      "F1 test: BaggingClassifier : 0.46805819101834284\n",
      "F1 train: RandomForestClassifier : 0.9998174849425077\n",
      "F1 test: RandomForestClassifier : 0.5274861025324274\n",
      "F1 train: AdaBoostClassifier : 0.569066344020972\n",
      "F1 test: AdaBoostClassifier : 0.5552165954850519\n",
      "F1 train: SVC : 0.4805102763997165\n",
      "F1 test: SVC : 0.46031746031746035\n"
     ]
    }
   ],
   "source": [
    "# Score using funciton: \n",
    "\n",
    "f1(lr, X_train, X_test, y_train, y_test)\n",
    "f1(knn, X_train, X_test, y_train, y_test)\n",
    "f1(cart, X_train, X_test, y_train, y_test)\n",
    "f1(bag, X_train, X_test, y_train, y_test)\n",
    "f1(rf, X_train, X_test, y_train, y_test)\n",
    "f1(adaboost, X_train, X_test, y_train, y_test)\n",
    "f1(svc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe highest delta between train and test F1 scores occur with the \n",
    "# Decision Tree Classifier, Bagging Classifier, and Random Forest Classifier. \n",
    "# To a lesser extent, the KNN is also overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would probably go with Adaboost or the Logistic Regression.\n",
    "# AdaBoost appears to be the least overfit with the highest F1 score,\n",
    "# And logistic regression has more interpretable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the above regression problems, I might explore more feature engineering around\n",
    "# squared terms, as was done with some of the variables provided, as well as \n",
    "# GridSearch to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
